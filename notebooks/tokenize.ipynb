{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESM3InferenceClient, ESMProtein, GenerationConfig\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import tqdm\n",
    "from esm.pretrained import ESM3_structure_encoder_v0, ESM3_structure_decoder_v0\n",
    "from esm.utils.structure.protein_chain import ProteinChain\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhf_BzJIqTFWGtAWOHOPUmaMTJmwbXXtxyCBFY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/huggingface_hub/_login.py:119\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_to_git_credential:\n\u001b[1;32m    113\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    114\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token has not been saved to the git credentials helper. Pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_to_git_credential=True` in this function directly or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--add-to-git-credential` if using via `huggingface-cli` if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou want to set the git credential as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         )\n\u001b[0;32m--> 119\u001b[0m     \u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_git_credential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_permission\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_permission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[1;32m    121\u001b[0m     notebook_login(new_session\u001b[38;5;241m=\u001b[39mnew_session, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/huggingface_hub/_login.py:410\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(token, add_to_git_credential, write_permission)\u001b[0m\n\u001b[1;32m    408\u001b[0m _save_token(token\u001b[38;5;241m=\u001b[39mtoken, token_name\u001b[38;5;241m=\u001b[39mtoken_name)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Set active token\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m \u001b[43m_set_active_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_git_credential\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogin successful.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _get_token_from_environment():\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/huggingface_hub/_login.py:468\u001b[0m, in \u001b[0;36m_set_active_token\u001b[0;34m(token_name, add_to_git_credential)\u001b[0m\n\u001b[1;32m    466\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(constants\u001b[38;5;241m.\u001b[39mHF_TOKEN_PATH)\n\u001b[1;32m    467\u001b[0m path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 468\u001b[0m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour token has been saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mHF_TOKEN_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/pathlib.py:1047\u001b[0m, in \u001b[0;36mPath.write_text\u001b[0;34m(self, data, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata must be str, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1045\u001b[0m                     data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1046\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1047\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "login(token= \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9164887788f41f2a4dd7f7112151270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1400ac13229b48b898b7600eb390ec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.41it/s]\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 18.96it/s]\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/utils/structure/protein_complex.py:223: UserWarning: Entity ID not found in metadata, using None as default\n",
      "  warnings.warn(\"Entity ID not found in metadata, using None as default\")\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 17.48it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 18.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESM3InferenceClient, ESMProtein, GenerationConfig\n",
    "\n",
    "# Will instruct you how to get an API key from huggingface hub, make one with \"Read\" permission.\n",
    "login()\n",
    "\n",
    "# This will download the model weights and instantiate the model on your machine.\n",
    "model: ESM3InferenceClient = ESM3.from_pretrained(\"esm3-open\").to(\"cuda\") # or \"cpu\"\n",
    "\n",
    "# Generate a completion for a partial Carbonic Anhydrase (2vvb)\n",
    "prompt = \"___________________________________________________DQATSLRILNNGHAFNVEFDDSQDKAVLKGGPLDGTYRLIQFHFHWGSLDGQGSEHTVDKKKYAAELHLVHWNTKYGDFGKAVQQPDGLAVLGIFLKVGSAKPGLQKVVDVLDSIKTKGKSADFTNFDPRGLLPESLDYWTYPGSLTTPP___________________________________________________________\"\n",
    "protein = ESMProtein(sequence=prompt)\n",
    "# Generate the sequence, then the structure. This will iteratively unmask the sequence track.\n",
    "protein = model.generate(protein, GenerationConfig(track=\"sequence\", num_steps=8, temperature=0.7))\n",
    "# We can show the predicted structure for the generated sequence.\n",
    "protein = model.generate(protein, GenerationConfig(track=\"structure\", num_steps=8))\n",
    "protein.to_pdb(\"./generation.pdb\")\n",
    "# Then we can do a round trip design by inverse folding the sequence and recomputing the structure\n",
    "protein.sequence = None\n",
    "protein = model.generate(protein, GenerationConfig(track=\"sequence\", num_steps=8))\n",
    "protein.coordinates = None\n",
    "protein = model.generate(protein, GenerationConfig(track=\"structure\", num_steps=8))\n",
    "protein.to_pdb(\"./round_tripped.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 18.94it/s]\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 18.89it/s]\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/utils/structure/protein_complex.py:223: UserWarning: Entity ID not found in metadata, using None as default\n",
      "  warnings.warn(\"Entity ID not found in metadata, using None as default\")\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 17.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 18.74it/s]\n"
     ]
    }
   ],
   "source": [
    "model: ESM3InferenceClient = ESM3.from_pretrained(\"esm3-open\").to(\"cuda\") # or \"cpu\"\n",
    "# Generate a completion for a partial Carbonic Anhydrase (2vvb)\n",
    "prompt = \"___________________________________________________DQATSLRILNNGHAFNVEFDDSQDKAVLKGGPLDGTYRLIQFHFHWGSLDGQGSEHTVDKKKYAAELHLVHWNTKYGDFGKAVQQPDGLAVLGIFLKVGSAKPGLQKVVDVLDSIKTKGKSADFTNFDPRGLLPESLDYWTYPGSLTTPP___________________________________________________________\"\n",
    "protein = ESMProtein(sequence=prompt)\n",
    "# Generate the sequence, then the structure. This will iteratively unmask the sequence track.\n",
    "protein = model.generate(protein, GenerationConfig(track=\"sequence\", num_steps=8, temperature=0.7))\n",
    "# We can show the predicted structure for the generated sequence.\n",
    "protein = model.generate(protein, GenerationConfig(track=\"structure\", num_steps=8))\n",
    "protein.to_pdb(\"./generation.pdb\")\n",
    "# Then we can do a round trip design by inverse folding the sequence and recomputing the structure\n",
    "protein.sequence = None\n",
    "protein = model.generate(protein, GenerationConfig(track=\"sequence\", num_steps=8))\n",
    "protein.coordinates = None\n",
    "protein = model.generate(protein, GenerationConfig(track=\"structure\", num_steps=8))\n",
    "protein.to_pdb(\"./round_tripped.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1j0k.cif',\n",
       " '3mal.cif',\n",
       " '3awu.cif',\n",
       " '6z4n.cif',\n",
       " '2oyh.cif',\n",
       " '4om4.cif',\n",
       " '5qz5.cif',\n",
       " '3upy.cif',\n",
       " '1vbg.cif',\n",
       " '8d7b.cif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb_arr = os.listdir('/manitou/pmg/projects/resources/openfold_data/data/pdb_mmcif/mmcif_files')\n",
    "pdb_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ESM3_structure_encoder_v0(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.116224"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 64/207540 [00:11<19:16:30,  2.99it/s]/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/biotite/structure/io/pdb/file.py:1189: UserWarning: Atom IDs exceed 99,999, will be wrapped\n",
      "  warnings.warn(f\"Atom IDs exceed {max_atoms:,}, will be wrapped\")\n",
      "  0%|          | 170/207540 [00:47<16:02:00,  3.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     cif_file \u001b[38;5;241m=\u001b[39m strucio\u001b[38;5;241m.\u001b[39mload_structure(file_path)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mstrucio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_write_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pdb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcif_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name, e)\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/biotite/structure/io/general.py:174\u001b[0m, in \u001b[0;36msave_structure\u001b[0;34m(file_path, array, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDBFile\n\u001b[1;32m    173\u001b[0m     file \u001b[38;5;241m=\u001b[39m PDBFile()\n\u001b[0;32m--> 174\u001b[0m     \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(file_path)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdbqt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/biotite/structure/io/pdb/file.py:677\u001b[0m, in \u001b[0;36mPDBFile.set_structure\u001b[0;34m(self, array, hybrid36)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_num\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Bundle non-coordinate data to simplify iteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 677\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m27\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m26\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    678\u001b[0m      \u001b[38;5;28;01mfor\u001b[39;00m start, (x, y, z), end \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    679\u001b[0m      \u001b[38;5;28mzip\u001b[39m(first_half, coord_i, second_half)]\n\u001b[1;32m    680\u001b[0m )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_stack:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENDMDL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import biotite.structure as struc\n",
    "import biotite.structure.io as strucio\n",
    "\n",
    "# Read the .mmcif file\n",
    "pdb_write_path= '/pmglocal/jb5005/struct_diff_data/pdb'\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(pdb_arr))):\n",
    "    file_path = os.path.join('/manitou/pmg/projects/resources/openfold_data/data/pdb_mmcif/mmcif_files', pdb_arr[i])\n",
    "    name = pdb_arr[i].split('.')[0]\n",
    "    try:\n",
    "        cif_file = strucio.load_structure(file_path)\n",
    "        strucio.save_structure(os.path.join(pdb_write_path, name + \".pdb\"), cif_file)\n",
    "    except Exception as e:\n",
    "        print(name, e)\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_structure_token(model, pdb):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    chain = read_pdb(pdb)\n",
    "    name = pdb.split('.')[0]\n",
    "    coords, plddt, residue_index = chain.to_structure_encoder_inputs()\n",
    "    coordinates = coords.to(device)\n",
    "    residue_index = residue_index.to(device)\n",
    "    _, structure_token = model.encode(coordinates, residue_index=residue_index)\n",
    "    structure_token = structure_token.squeeze(0).cpu().numpy()\n",
    "    np.save(\n",
    "        \"/pmglocal/jb5005/struct_diff_data/tokens/\" + name + \".npy\",\n",
    "        structure_token\n",
    "    )\n",
    "    return structure_token\n",
    "\n",
    "\n",
    "def read_pdb(pdb_file, id=None, chain_id=\"A\"):\n",
    "    \"\"\"Read a PDB file and return a ProteinChain object.\"\"\"    \n",
    "    pdb_file = os.path.join(pdb_write_path, pdb_file)\n",
    "    return ProteinChain.from_pdb(pdb_file, id=id, chain_id=chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EEVETFAFQAEIAQLMSLIINTFYSNKEIFLRELISNSSDALDKIRYESLTDPSKLDSGKELHINLIPNKQDRTLTIVDTGIGMTKADLINNLGTIAKSGTKAFMEALQAGADISMIGQFGVGFYSAYLVAEKVTVITKHNDDEQYAWESSAGGSFTVRTDTGEPMGRGTKVILHLKEDQTEYLEERRIKEIVKKHSQFIGYPITLFVE'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ProteinChain.from_pdb(\"/burg/home/jb5005/6f1n.pdb\", id=None, chain_id='detect')\n",
    "coords, plddt, residue_index = chain.to_structure_encoder_inputs()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ESM3_structure_encoder_v0(device=device)\n",
    "coordinates = coords.to(device)\n",
    "residue_index = residue_index.to(device)\n",
    "_, structure_token = model.encode(coordinates, residue_index=residue_index)\n",
    "\n",
    "chain.sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n",
      "  1%|          | 1/168 [00:01<03:53,  1.40s/it]/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/models/vqvae.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=False):  # type: ignore\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 128/168 [00:22<00:07,  5.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdb_file \u001b[38;5;129;01min\u001b[39;00m tqdm(pdb_files):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# start = time.time()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mpartial_get_structure_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(pdb_file, e)    \n",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m, in \u001b[0;36mget_structure_token\u001b[0;34m(model, pdb)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_structure_token\u001b[39m(model, pdb):\n\u001b[1;32m      4\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     chain \u001b[38;5;241m=\u001b[39m \u001b[43mread_pdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     name \u001b[38;5;241m=\u001b[39m pdb\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     coords, plddt, residue_index \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mto_structure_encoder_inputs()\n",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m, in \u001b[0;36mread_pdb\u001b[0;34m(pdb_file, id, chain_id)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read a PDB file and return a ProteinChain object.\"\"\"\u001b[39;00m    \n\u001b[1;32m     21\u001b[0m pdb_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pdb_write_path, pdb_file)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mProteinChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/utils/structure/protein_chain.py:558\u001b[0m, in \u001b[0;36mProteinChain.from_pdb\u001b[0;34m(cls, path, chain_id, id, is_predicted)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m    556\u001b[0m             file_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 558\u001b[0m atom_array \u001b[38;5;241m=\u001b[39m \u001b[43mPDBFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_factor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    562\u001b[0m     chain_id \u001b[38;5;241m=\u001b[39m atom_array\u001b[38;5;241m.\u001b[39mchain_id[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/biotite/structure/io/pdb/file.py:418\u001b[0m, in \u001b[0;36mPDBFile.get_structure\u001b[0;34m(self, model, altloc, extra_fields, include_bonds)\u001b[0m\n\u001b[1;32m    416\u001b[0m atom_name[i] \u001b[38;5;241m=\u001b[39m line[_atom_name]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    417\u001b[0m element[i] \u001b[38;5;241m=\u001b[39m line[_element]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m--> 418\u001b[0m \u001b[43maltloc_id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m line[_alt_loc]\n\u001b[1;32m    419\u001b[0m atom_id_raw[i] \u001b[38;5;241m=\u001b[39m line[_atom_id]\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# turn \"1-\" into \"-1\", if necessary\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ESM3_structure_encoder_v0(device=device)\n",
    "model.eval()\n",
    "\n",
    "pdb_files = os.listdir(pdb_write_path)\n",
    "\n",
    "partial_get_structure_token = partial(get_structure_token, model)\n",
    "# get the structure token for each domain in a multiprocessing way with tqdm    \n",
    "for pdb_file in tqdm(pdb_files):\n",
    "    # start = time.time()\n",
    "    try:\n",
    "        partial_get_structure_token(pdb_file)\n",
    "    except Exception as e:\n",
    "        print(pdb_file, e)    \n",
    "    # print(f\"Time taken for {pdb_file}: {time.time() - start}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2765"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/pmglocal/jb5005/struct_diff_data/tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pmglocal/jb5005/mambaforge/envs/struct_diff/lib/python3.12/site-packages/esm/pretrained.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "decoder = ESM3_structure_decoder_v0(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1280])\n",
      "Time taken for embedding: 0.0007746219635009766\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "arr = np.arange(0,1000)\n",
    "print(decoder.embed(torch.tensor(arr, device = device)).shape)\n",
    "print(f\"Time taken for embedding: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0874, -0.1162, -0.0120,  ..., -0.0522, -0.0076, -0.0469],\n",
       "        [-0.0781,  0.0840, -0.0781,  ...,  0.0569, -0.0199,  0.0126],\n",
       "        [ 0.1182, -0.0540,  0.0110,  ...,  0.0289, -0.0299, -0.0281],\n",
       "        ...,\n",
       "        [ 0.0042,  0.0229, -0.0276,  ...,  0.0077,  0.0469, -0.0698],\n",
       "        [ 0.0082, -0.0020, -0.0089,  ..., -0.0554, -0.0713,  0.0305],\n",
       "        [ 0.0249, -0.0054,  0.0128,  ...,  0.0273,  0.0452, -0.0515]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.embed(torch.tensor(arr, device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "struct_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
